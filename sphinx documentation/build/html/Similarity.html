

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Similarity &mdash; Sphinx_doc 2021 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="LDA analysis" href="LdaAnalysis.html" />
    <link rel="prev" title="Inference" href="Inference.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Sphinx_doc
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="indexModule.html">Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Dataset_function.html">Dataset function</a></li>
<li class="toctree-l2"><a class="reference internal" href="Preprocess.html">Preprocess</a></li>
<li class="toctree-l2"><a class="reference internal" href="TopicModel.html">Topic Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="Inference.html">Inference</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="LdaAnalysis.html">LDA analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="indexApp.html">Application</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Sphinx_doc</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="indexModule.html">Model</a> &raquo;</li>
        
      <li>Similarity</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/Similarity.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-Similarity">
<span id="similarity"></span><h1>Similarity<a class="headerlink" href="#module-Similarity" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="Similarity.Similarity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">Similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_inference</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_inference</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to proceed to each similarity tools including finding the most similar document, measure evaluation and repartition of similarity score</p>
<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.evaluation">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">evaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.evaluation" title="Permalink to this definition">¶</a></dt>
<dd><p>Each doc of teh validation dataset will pass as target docuemnt. We are tring to predict the most similar document to the target.
This is measured by the rate of same common field and the rate of at least one common tag between teh target document and the document
predicted as the most similar.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.evaluation2">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">evaluation2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.evaluation2" title="Permalink to this definition">¶</a></dt>
<dd><p>Each doc of teh validation dataset will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set.</p>
<blockquote>
<div><p>This is measured by the rate of same common field and the rate of at least one common tag between the
target document and the N most similar documents.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.most_similar_sorted">
<span class="sig-name descname"><span class="pre">most_similar_sorted</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">id_doc_infer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.most_similar_sorted" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all similarity between an unique document from the inference model and all document from the training set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>id_doc_infer</strong> – index of the document wanted to infer for similarity</p></li>
<li><p><strong>learning_rate</strong> – it should be include between 0 and 1</p></li>
<li><p><strong>measure</strong> – similarity measure</p></li>
<li><p><strong>normalize</strong> – True of normalization wanted False otherwise</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ID doc list sorted ascending by similarity score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.most_similar_sorted_eval">
<span class="sig-name descname"><span class="pre">most_similar_sorted_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">id_doc_infer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.most_similar_sorted_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the similarity between a single document from the inferenced model and all other document from the same model (excluding himself)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>id_doc_infer</strong> – index of the document wanted to infer for similarity</p></li>
<li><p><strong>learning_rate</strong> – it should be include between 0 and 1</p></li>
<li><p><strong>measure</strong> – similarity measure</p></li>
<li><p><strong>normalize</strong> – True of normalization wanted False otherwise</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ID doc list sorted ascending by similarity score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.repartition_similarity">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">repartition_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.repartition_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>For each field, 10 documents will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set. We plot a colored  rectangle (color depend of the field) for the N most similar document found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>figure according to the function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.same_prediction">
<span class="sig-name descname"><span class="pre">same_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.same_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Creating a dataframe who gathered the ratio of same prediction between all similarity score for all pair of document from the model 1 and model 2 based according to each measure</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>weights</strong> – a dictionary with similarity measure as keys and learning_rate choosen following the key as value</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dataframe who is composed of the ratio of same prediction between 2 similarity measure.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.similarity_distribution">
<span class="sig-name descname"><span class="pre">similarity_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">id_doc_infer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.similarity_distribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the similarity score distribution with all similarity measure between an single validation document and the entire training set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>id_doc_infer</strong> – index of the document wanted as target for similarity</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.similarity_distribution_eval">
<span class="sig-name descname"><span class="pre">similarity_distribution_eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">id_doc_infer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.similarity_distribution_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the similarity score distribution with all similarity measure between an single validation document and the entire training set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>id_doc_infer</strong> – index of the document wanted as target for similarity</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.Similarity.similarity_score">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">similarity_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Similarity.similarity_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Similarity score between two document based on the document topic distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>body_distribution1</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>body_distribution2</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>abstract_distribution1</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>abstract_distribution2</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>learning_rate</strong> – it should be include between 0 and 1</p></li>
<li><p><strong>measure</strong> – similarity measure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Similarity.SimilarityV1V3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">SimilarityV1V3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_inference</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_inference</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV1V3" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to implement version 1 and version 3. The difference will be if abstract and body have been
trained with the same number of topics(V3) or not (V1)</p>
<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV1V3.evaluation">
<span class="sig-name descname"><span class="pre">evaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV1V3.evaluation" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Each doc of teh validation dataset will pass as target docuemnt. We are tring to predict the most similar document to the target.
This is measured by the rate of same common field and the rate of at least one common tag between teh target document and the document
predicted as the most similar.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV1V3.evaluation2">
<span class="sig-name descname"><span class="pre">evaluation2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV1V3.evaluation2" title="Permalink to this definition">¶</a></dt>
<dd><p>Each doc of teh validation dataset will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set.
This is measured by the rate of same common field and the rate of at least one common tag between the
target document and the N most similar documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV1V3.repartition_similarity">
<span class="sig-name descname"><span class="pre">repartition_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV1V3.repartition_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>For each field, 10 documents will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set. We plot a colored  rectangle (color depend of the field) for the N most similar document found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>figure according to the function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV1V3.similarity_score">
<span class="sig-name descname"><span class="pre">similarity_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV1V3.similarity_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Similarity score between the document-topic distribution for abstract from the training set and from the
validation set (inference) and similarity score between the document-topic distribution for body from the training set
and from the validation set(inference). A learning rate has been added to see how giving more weight to the abstract
score or the body score influence the output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>body_distribution1</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>body_distribution2</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>abstract_distribution1</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>abstract_distribution2</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>learning_rate</strong> – it should be include between 0 and 1</p></li>
<li><p><strong>measure</strong> – similarity measure</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>similarity score according the first idea version.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="Similarity.SimilarityV2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">SimilarityV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_inference</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_inference</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Class to implement version 2.
..warning:  abstract and body must have been trained with the same number of topics</p>
<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.evaluation">
<span class="sig-name descname"><span class="pre">evaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.evaluation" title="Permalink to this definition">¶</a></dt>
<dd><p>Each doc of teh validation dataset will pass as target docuemnt. We are tring to predict the most similar document to the target.
This is measured by the rate of same common field and the rate of at least one common tag between teh target document and the document
predicted as the most similar.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.evaluation2">
<span class="sig-name descname"><span class="pre">evaluation2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.evaluation2" title="Permalink to this definition">¶</a></dt>
<dd><p>Each doc of teh validation dataset will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set.
This is measured by the rate of same common field and the rate of at least one common tag between the
target document and the N most similar documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two dictionary of confusion matrix for each measure and each measure</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.reorganization_topic">
<span class="sig-name descname"><span class="pre">reorganization_topic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx_translation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.reorganization_topic" title="Permalink to this definition">¶</a></dt>
<dd><p>We will reorganized all validation document-topic distribution according the topic_translation above</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>idx_translation</strong> – output from topic_translation()</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.repartition_similarity">
<span class="sig-name descname"><span class="pre">repartition_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe_eval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measures</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.repartition_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>For each field, 10 documents will pass as target document. We are trying to predict the N most similar
document to the target where N is the number of document with same field as target document inside the
evaluation set. We plot a colored  rectangle (color depend of the field) for the N most similar document found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe_eval</strong> – dataframe of the evaluation set</p></li>
<li><p><strong>measures</strong> – similarity measure list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>figure according to the function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.similarity_score">
<span class="sig-name descname"><span class="pre">similarity_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">body_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">body_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abstract_distribution2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.similarity_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Similarity score between the document-topic distribution for abstracts from the training set and bodies
from the validation set and similarity score between the document-topic distribution for bodies from the
training set and abstracts from the validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>body_distribution1</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>body_distribution2</strong> – Document topic distribution for a single document with body model</p></li>
<li><p><strong>abstract_distribution1</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>abstract_distribution2</strong> – Document topic distribution for a single document with abstract model</p></li>
<li><p><strong>learning_rate</strong> – it should be include between 0 and 1</p></li>
<li><p><strong>measure</strong> – similarity measure</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>similarity score according the first idea version.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Similarity.SimilarityV2.topic_translation">
<span class="sig-name descname"><span class="pre">topic_translation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synset_translation_body</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synset_translation_abstract</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.SimilarityV2.topic_translation" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>For the second version, as the training set and validation isn’t related to the same model, topic order is
likely to change between two model. This function aims to compute similarity between topics from the two
model to find which topic from the model 2 is related for the model 1</p>
<dl class="field-list simple">
<dt class="field-odd">param synset_translation_body</dt>
<dd class="field-odd"><p>output from synset_translation with bodies</p>
</dd>
<dt class="field-even">param synset_translation_abstract</dt>
<dd class="field-even"><p>output from synset_translation with abstracts</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>list of tuples where the first element is the subject ID of model 1 and the second element is the subject ID linked to model 2</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.Wu_Palmer_similarity">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">Wu_Palmer_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_word1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topic_word2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.Wu_Palmer_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute similarity between 2 topics based on Wu-Palmer similarity that gives us a score of similarity between two Synset.
Note : We need to have a Synset as key of each dictionary. Wu-Palmer similarity attribute 1 if the word are the same and 0 if they are opposite.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>topics_word1</strong> – dictionary of word-topic distribution for a single topic</p></li>
<li><p><strong>topics_word2</strong> – dictionary of word-topic distribution for a single topic</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the similarity score between two topics that will represent the average of all Wup similarity score between all word of each model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.preprocess3_to_topic_word_Synset">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">preprocess3_to_topic_word_Synset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">synset_translation_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_topic_distribution</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.preprocess3_to_topic_word_Synset" title="Permalink to this definition">¶</a></dt>
<dd><p>The goal of this function is to have the same topic_word output but with synset name as key</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>synset_translation_dict</strong> – output from the function synset_translation()</p></li>
<li><p><strong>word_topic_distribution</strong> – word_topic_distribution from a LDA model trained with Preprocessing 3</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>same word_topic_distribution with only Synset name as key</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.remove_topic">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">remove_topic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">liste</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topic1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topic2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.remove_topic" title="Permalink to this definition">¶</a></dt>
<dd><p>From a tuple list like(topic1,topic2,similarity score) we remove all tuple who has topic1 as tuple[0] and topic2
as tuple[1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>liste</strong> – tuple list where each tuple is composed as (topic1,topic2,score_similarity)</p></li>
<li><p><strong>topic1</strong> – a topic from an LDA model trained</p></li>
<li><p><strong>topic2</strong> – a topic from an LDA model trained</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list without occurence of topic 1 and topic 2 inside tuples</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.search_min">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">search_min</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">liste</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.search_min" title="Permalink to this definition">¶</a></dt>
<dd><p>Finding the minimum inside a list of tuple</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>liste</strong> – tuple list where each tuple is composed as (topic1,topic2,score_similarity)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the tuple with the smallest similiarity score (0 = same)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.similarity">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx_doc1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx_doc2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measure</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the distance score between two distribution depending on the measure in parameter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idx_doc1</strong> – topic distribution of the first document</p></li>
<li><p><strong>idx_doc2</strong> – topic distribution of the second document</p></li>
<li><p><strong>measure</strong> – name of the distance measure wanted</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>similarity score</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="Similarity.synset_translation">
<span class="sig-prename descclassname"><span class="pre">Similarity.</span></span><span class="sig-name descname"><span class="pre">synset_translation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Similarity.synset_translation" title="Permalink to this definition">¶</a></dt>
<dd><p>The goal of this function is to create a dictionary composed of token from the corpus preprocessed  as key and his synset translation as value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> – preprocessed text</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary of translation between word and</p>
</dd>
</dl>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="LdaAnalysis.html" class="btn btn-neutral float-right" title="LDA analysis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Inference.html" class="btn btn-neutral float-left" title="Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, POUILLOT Samuel / SENDRA Thomas.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>